import os
import uuid
import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
from graph import create_chat_graph

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LangGraph Chat",
    page_icon="ğŸ’¬",
    layout="wide"
)

# í—¬í¼ í•¨ìˆ˜: LangGraph stateì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
def get_messages():
    """LangGraphì˜ stateì—ì„œ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not st.session_state.graph:
        return []
    
    try:
        config = {"configurable": {"thread_id": st.session_state.thread_id}}
        state = st.session_state.graph.get_state(config)
        
        messages = []
        if state.values.get("messages"):
            for msg in state.values["messages"]:
                if hasattr(msg, '__class__'):
                    msg_type = msg.__class__.__name__
                    if msg_type == "HumanMessage":
                        messages.append({"role": "user", "content": msg.content})
                    elif msg_type == "AIMessage":
                        messages.append({"role": "assistant", "content": msg.content})
        return messages
    except Exception:
        return []

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "graph" not in st.session_state:
    st.session_state.graph = None
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ’¬ LangGraph Chat")
    st.divider()
    
    # API í‚¤ ì„¤ì •
    api_key = st.text_input(
        "Google Gemini API í‚¤",
        type="password",
        value=os.getenv("GOOGLE_API_KEY", ""),
        help="Google AI Studioì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”: https://makersuite.google.com/app/apikey"
    )
    
    model_option = st.radio(
        "ëª¨ë¸ ì„ íƒ",
        ["ê¸°ë³¸ ëª¨ë¸", "ì§ì ‘ ì…ë ¥"],
        index=0,
        horizontal=True
    )
    
    if model_option == "ê¸°ë³¸ ëª¨ë¸":
        model_name = st.selectbox(
            "ëª¨ë¸",
            [
                "gemini-3-pro-preview",
                "gemini-3-flash-preview",
                "gemini-2.5-flash",
                "gemini-2.5-pro",
                "gemini-2.0-flash-exp",
                "gemini-2.0-flash-lite",
                "gemini-1.5-pro",
                "gemini-1.5-flash",
                "gemini-1.5-flash-8b",
                "gemini-pro",
            ],
            index=2,
            label_visibility="collapsed"
        )
    else:
        model_name = st.text_input(
            "ëª¨ë¸ ì´ë¦„",
            value="gemini-2.5-pro",
            placeholder="ì˜ˆ: gemini-3-pro-preview, gemini-2.0-flash-lite, gemini-1.5-flash-8b",
            help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
        )
    
    if api_key:
        if st.session_state.graph is None or st.session_state.get("current_api_key") != api_key or st.session_state.get("current_model") != model_name:
            try:
                with st.spinner("ê·¸ë˜í”„ ì´ˆê¸°í™” ì¤‘..."):
                    st.session_state.graph = create_chat_graph(api_key, model_name)
                    st.session_state.current_api_key = api_key
                    st.session_state.current_model = model_name
                
                st.success("âœ… ê·¸ë˜í”„ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"âŒ ê·¸ë˜í”„ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                st.session_state.graph = None
    else:
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
        st.session_state.graph = None
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°", use_container_width=True):
        # ìƒˆë¡œìš´ thread_id ìƒì„±ìœ¼ë¡œ ëŒ€í™” ì´ˆê¸°í™”
        st.session_state.thread_id = str(uuid.uuid4())
        st.rerun()
    
    st.divider()
    st.caption("LangGraphì™€ Streamlitì„ ì‚¬ìš©í•œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤")

# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ’¬ ì±„íŒ…")

# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ (LangGraph stateì—ì„œ ê°€ì ¸ì˜¤ê¸°)
messages = get_messages()
for message in messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # API í‚¤ í™•ì¸
    if not st.session_state.graph:
        st.error("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ìƒì„± ì¤‘..."):
            try:
                # LangGraph ì‹¤í–‰ (checkpointerê°€ ìë™ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ ê´€ë¦¬)
                config = {"configurable": {"thread_id": st.session_state.thread_id}}
                result = st.session_state.graph.invoke(
                    {"messages": [HumanMessage(content=prompt)]},
                    config=config
                )
                
                # ë§ˆì§€ë§‰ AI ì‘ë‹µ ì¶”ì¶œ ë° í‘œì‹œ
                if result.get("messages"):
                    last_message = result["messages"][-1]
                    response = last_message.content if hasattr(last_message, 'content') else str(last_message)
                else:
                    response = "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                st.markdown(response)
                
                # ì„±ê³µ ì‹œì—ë§Œ í˜ì´ì§€ ë¦¬ë¡œë“œ
                st.rerun()
                
            except Exception as e:
                error_msg = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                st.error(error_msg)
                # ì—ëŸ¬ ë°œìƒ ì‹œì—ëŠ” reruní•˜ì§€ ì•Šì•„ì„œ ì—ëŸ¬ ë©”ì‹œì§€ê°€ í™”ë©´ì— ë‚¨ë„ë¡ í•¨
