import os
import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
from graph import create_chat_graph

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LangGraph Chat",
    page_icon="ğŸ’¬",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "graph" not in st.session_state:
    st.session_state.graph = None

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title("ğŸ’¬ LangGraph Chat")
    st.divider()
    
    # API í‚¤ ì„¤ì •
    api_key = st.text_input(
        "Google Gemini API í‚¤",
        type="password",
        value=os.getenv("GOOGLE_API_KEY", ""),
        help="Google AI Studioì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”: https://makersuite.google.com/app/apikey"
    )
    
    model_option = st.radio(
        "ëª¨ë¸ ì„ íƒ",
        ["ê¸°ë³¸ ëª¨ë¸", "ì§ì ‘ ì…ë ¥"],
        index=0,
        horizontal=True
    )
    
    if model_option == "ê¸°ë³¸ ëª¨ë¸":
        model_name = st.selectbox(
            "ëª¨ë¸",
            [
                "gemini-2.5-flash",
                "gemini-2.5-pro",
                "gemini-2.0-flash-exp",
                "gemini-1.5-pro",
                "gemini-1.5-flash",
                "gemini-pro",
            ],
            index=0,
            label_visibility="collapsed"
        )
    else:
        model_name = st.text_input(
            "ëª¨ë¸ ì´ë¦„",
            value="gemini-2.5-pro",
            placeholder="ì˜ˆ: gemini-2.5-pro, gemini-2.5-flash",
            help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
        )
    
    if api_key:
        if st.session_state.graph is None or st.session_state.get("current_api_key") != api_key or st.session_state.get("current_model") != model_name:
            try:
                with st.spinner("ê·¸ë˜í”„ ì´ˆê¸°í™” ì¤‘..."):
                    st.session_state.graph = create_chat_graph(api_key, model_name)
                    st.session_state.current_api_key = api_key
                    st.session_state.current_model = model_name
                st.success("âœ… ê·¸ë˜í”„ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"âŒ ê·¸ë˜í”„ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                st.session_state.graph = None
    else:
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
        st.session_state.graph = None
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    st.caption("LangGraphì™€ Streamlitì„ ì‚¬ìš©í•œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤")

# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ’¬ ì±„íŒ…")

# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # API í‚¤ í™•ì¸
    if not st.session_state.graph:
        st.error("âš ï¸ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ìƒì„± ì¤‘..."):
            try:
                # LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                langchain_messages = []
                for msg in st.session_state.messages:
                    if msg["role"] == "user":
                        langchain_messages.append(HumanMessage(content=msg["content"]))
                    elif msg["role"] == "assistant":
                        langchain_messages.append(AIMessage(content=msg["content"]))
                
                # LangGraph ì‹¤í–‰
                result = st.session_state.graph.invoke({"messages": langchain_messages})
                
                # ë§ˆì§€ë§‰ AI ì‘ë‹µ ì¶”ì¶œ
                if result.get("messages"):
                    last_message = result["messages"][-1]
                    response = last_message.content if hasattr(last_message, 'content') else str(last_message)
                else:
                    response = "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
            except Exception as e:
                error_msg = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})
