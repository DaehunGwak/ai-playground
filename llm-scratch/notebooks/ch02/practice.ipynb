{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30307151",
   "metadata": {},
   "source": [
    "# Ch 02\n",
    "\n",
    "토큰화 > 임베딩에 주 목적\n",
    "\n",
    "## 1) 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493b66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
      "\n",
      "\"The height of his glory\"--that was what the women called it. I can hear\n"
     ]
    }
   ],
   "source": [
    "with open('The Verdict.txt', 'r') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(len(raw_text))\n",
    "print(raw_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65037d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 수: 4728\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 공백 기준 분리 + 특수 문자를 별도 토큰으로 추출\n",
    "# -- 는 하나의 토큰, 나머지 특수 문자는 개별 토큰\n",
    "tokens = re.findall(r'--|[^\\s,.\\-:;?_!\"()`\\']+|[,.:;?_!\"()`\\']', raw_text)\n",
    "\n",
    "print(f\"토큰 수: {len(tokens)}\")\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587a0e6",
   "metadata": {},
   "source": [
    "## 2.3 토큰을 토큰 ID 로 변환\n",
    "\n",
    "- 어휘 사전(vocabulary) 구축 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67062dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(tokens))\n",
    "vocab_size = len(all_words)\n",
    "vocab = {token: i for i, token in enumerate(all_words)}\n",
    "\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if (i >= 50):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004f6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 토크나이저 구현\n",
    "\n",
    "class SimpleTokenizerV1:\n",
    "    # 특수 문자 목록\n",
    "    special_tokens = {'--', ',', '.', ':', ';', '?', '_', '!', '\"', '(', ')', '`', \"'\"}\n",
    "\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.findall(r'--|[^\\s,.\\-:;?_!\"()`\\']+|[,.:;?_!\"()`\\']', text)\n",
    "        ids = [self.str_to_int[token] for token in preprocessed if token in self.str_to_int]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        tokens = [self.int_to_str[id] for id in ids]\n",
    "        # 첫 토큰은 그대로, 이후 단어 앞에만 공백 추가\n",
    "        # 특수 문자 앞에는 공백 없음, -- 뒤에는 공백 없음\n",
    "        result = []\n",
    "        for i, token in enumerate(tokens):\n",
    "            if i == 0 or token in self.special_tokens or tokens[i - 1] == '--':\n",
    "                result.append(token)\n",
    "            else:\n",
    "                result.append(' ' + token)\n",
    "        return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5fc8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69, 1007, 726, 588, 5, 701, 325, 440, 6, 161, 689, 995, 569, 53, 2, 315, 711, 1032, 115, 236, 7]\n",
      "Never think of it, my dear fellow--any more than if I' d never touched a brush.\n"
     ]
    }
   ],
   "source": [
    "# encode test\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "ids = tokenizer.encode(\"Never think of it, my dear fellow--any more than if I'd never touched a brush.\")\n",
    "\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47793c1d",
   "metadata": {},
   "source": [
    "## 2.4 특수 문맥 토큰 추가하기\n",
    "\n",
    "비식별 문자에 대해 토큰 남기는 것\n",
    "- `<|unk|>` : 사전에 없는 정보 토큰 대체\n",
    "- `<|endoftext|>` : 관련이 없는 텍스트 사이 대체 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb1c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 수: 1141\n",
      "[('younger', 1136), ('your', 1137), ('yourself', 1138), ('<|endoftext|>', 1139), ('<|unk|>', 1140)]\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(set(tokens))\n",
    "all_tokens.extend(['<|endoftext|>', '<|unk|>'])\n",
    "vocab = {token: i for i, token in enumerate(all_tokens)}\n",
    "\n",
    "print(f\"토큰 수: {len(vocab)}\")\n",
    "print(list(vocab.items())[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c672c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    # 특수 문자 목록\n",
    "    special_tokens = {'--', ',', '.', ':', ';', '?', '_', '!', '\"', '(', ')', '`', \"'\"}\n",
    "\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.findall(r'--|[^\\s,.\\-:;?_!\"()`\\']+|[,.:;?_!\"()`\\']', text)\n",
    "        preprocessed = [item if item in self.str_to_int else '<|unk|>' for item in preprocessed]\n",
    "        ids = [self.str_to_int[token] for token in preprocessed if token in self.str_to_int]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        tokens = [self.int_to_str[id] for id in ids]\n",
    "        # 첫 토큰은 그대로, 이후 단어 앞에만 공백 추가\n",
    "        # 특수 문자 앞에는 공백 없음, -- 뒤에는 공백 없음\n",
    "        result = []\n",
    "        for i, token in enumerate(tokens):\n",
    "            if i == 0 or token in self.special_tokens or tokens[i - 1] == '--':\n",
    "                result.append(token)\n",
    "            else:\n",
    "                result.append(' ' + token)\n",
    "        return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3bf688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join([text1, text2])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0adf483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1140, 5, 361, 1135, 630, 984, 10, 1139, 55, 997, 965, 993, 726, 997, 1140, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a1215",
   "metadata": {},
   "source": [
    "추가 특수 토큰\n",
    "- `[BOS]` (beginning of sequence)\n",
    "- `[EOS]` (end of sequence)\n",
    "- `[PAD]` (padding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fad0d",
   "metadata": {},
   "source": [
    "## 2.5 바이트 페어 인코딩\n",
    "\n",
    "- `<|unk|>` 토큰 사용 대신 단어를 부분 단어로 분할하는 byte pair encoding(BPE) 토크나이저를 사용\n",
    "- BPE 는 구현이 복잡해 `tiktoken` 라이브러리 사용 예정\n",
    "- 잘 알지 못하는 단어는 개별 문자 or 부분 문자로 토큰화 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acaaafe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "\n",
    "print(version('tiktoken'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa588658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 2954, 593, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunkownPlace.\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33320972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunkownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121df783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akwirw ier [33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "source": [
    "## 연습문제 2.1\n",
    "sample_text = \"Akwirw ier\"\n",
    "encoded = tokenizer.encode(sample_text)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de4c17",
   "metadata": {},
   "source": [
    "## 2.6 슬라이딩 윈도로 데이터 샘플링하기\n",
    "\n",
    "- 이때까지 토크나이징, 문자 임베딩을 살펴봄\n",
    "- 이제 학습용으로 입력-타겟 쌍을 생성 해야함\n",
    "- LLM 은 텍스트에 있는 다음 단어를 예측하는 식으로 사전 훈련 됨\n",
    "- 슬라이딩 윈도우로 하나씩 데이터를 쪼개서 만들어 볼 예정\n",
    "- torch Dataset, DataLoader 는 부록 A - 1.3 절 참고\n",
    "- batch_size 는 LLM 학습에서 하이퍼 파라미터라고 불림\n",
    "  - batch_size 가 커질수록 메모리는 많이 차지하지만, 데이터 잡음이 조금씩 줄을 수 있음\n",
    "  - trade-off: 배치 크기에 대해서도 튜닝 가능한 옵션 > 하이퍼 파라미터라 부름\n",
    "- 배치 사이에 중첩이 있으면 과대적합(overfitting) 이 증가할 수 있는데, 최대한 input 데이터 중첩을 피해서 과대적합을 방지할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "761987f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n",
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438, 568, 340, 373, 645, 1049, 5975, 284, 502, 284, 3285, 326, 11, 287, 262, 6001, 286, 465, 13476, 11, 339, 550, 5710, 465, 12036, 11, 6405, 257, 5527, 27075, 11, 290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686, 41976, 13, 357, 10915, 314, 2138, 1807, 340, 561, 423, 587, 10598, 393, 28537, 2014, 198, 198, 1, 464, 6001, 286, 465, 13476, 1, 438, 5562, 373, 644, 262, 1466, 1444, 340, 13, 314, 460, 3285, 9074, 13, 46606, 536]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "with open('The Verdict.txt', 'r') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))\n",
    "print(enc_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa25277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "enc_sample = enc_text[50:]\n",
    "\n",
    "context_size = 4\n",
    "x = enc_sample[ : context_size]\n",
    "y = enc_sample[1 : context_size + 1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b124d611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: [290] -> target: 4920\n",
      "context: [290, 4920] -> target: 2241\n",
      "context: [290, 4920, 2241] -> target: 287\n",
      "context: [290, 4920, 2241, 287] -> target: 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    context= enc_sample[:i]\n",
    "    target = enc_sample[i]\n",
    "    print(f\"context: {context} -> target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9694a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  and -> target:  established\n",
      "context:  and established -> target:  himself\n",
      "context:  and established himself -> target:  in\n",
      "context:  and established himself in -> target:  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size + 1):\n",
    "    context= enc_sample[:i]\n",
    "    target = enc_sample[i]\n",
    "    print(f\"context: {tokenizer.decode(context)} -> target: {tokenizer.decode([target])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6875a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8539d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128,\n",
    "                        shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last, # 마지막 배치가 데이터 수와 일치하지 않으면 버림\n",
    "        num_workers=num_workers # 전처리에 사용할 cpu 수\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7703be37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  40,  367, 2885, 1464]])\n",
      "tensor([[ 367, 2885, 1464, 1807]])\n"
     ]
    }
   ],
   "source": [
    "with open('The Verdict.txt', 'r') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch[0]) # 입력 데이터\n",
    "print(first_batch[1]) # 타겟 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef29bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 367, 2885, 1464, 1807]])\n",
      "tensor([[2885, 1464, 1807, 3619]])\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch[0])\n",
    "print(second_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2528f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length=2, stride=2\n",
      "first batch:\n",
      "tensor([[ 40, 367]])\n",
      "tensor([[ 367, 2885]])\n",
      "second batch:\n",
      "tensor([[2885, 1464]])\n",
      "tensor([[1464, 1807]])\n"
     ]
    }
   ],
   "source": [
    "# 연습문제 2.2: 여러가지 스트라이드와 문맥 크기를 가진 데이터 로더 만들기\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=2, stride=2, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(\"max_length=2, stride=2\")\n",
    "print(\"first batch:\")\n",
    "print(first_batch[0])\n",
    "print(first_batch[1])\n",
    "\n",
    "second_batch = next(data_iter)\n",
    "print(\"second batch:\")\n",
    "print(second_batch[0])\n",
    "print(second_batch[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b539340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length=8, stride=2\n",
      "first batch:\n",
      "tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]])\n",
      "tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])\n",
      "second batch:\n",
      "tensor([[ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138]])\n",
      "tensor([[ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=8, stride=2, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(\"max_length=8, stride=2\")\n",
    "print(\"first batch:\")\n",
    "print(first_batch[0])\n",
    "print(first_batch[1])\n",
    "\n",
    "second_batch = next(data_iter)\n",
    "print(\"second batch:\")\n",
    "print(second_batch[0])\n",
    "print(second_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418d9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=4, stride=4, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7eba5",
   "metadata": {},
   "source": [
    "## 2.7 토큰 임베딩 만들기\n",
    "\n",
    "- 토큰 ID 를 임베딩 벡터로 변환 필요\n",
    "- 역전파(backpropagation) 알고리즘으로 훈련하는 방법은 부록 A - A.4 절 참고\n",
    "- `torch.nn.Embedding`: 원-핫 인코딩방식의 sparse 한 방식을 최적화해서 구현해놓은 것\n",
    "  - 인덱스 룩업을 통해 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38c91336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "vocab_size = 6\n",
    "output_dim = 3 # 임베딩 벡터 차원 (GPT-3 임베딩 크기는 12288)\n",
    "\n",
    "torch.manual_seed(123) # 결과 재현을 위한 시드값 고정\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "print(embedding_layer.weight) # 6개의 토큰이 하나의 행에 할당, 열이 6개가 됨\n",
    "print(embedding_layer(torch.tensor([3]))) # 토큰 3의 임베딩 벡터 출력\n",
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6985dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Embedding                                [4, 3]                    18\n",
       "==========================================================================================\n",
       "Total params: 18\n",
       "Trainable params: 18\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(embedding_layer, input_data=input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827326d",
   "metadata": {},
   "source": [
    "## 2.8 단어 위치 인코딩 하기\n",
    "\n",
    "- LLM 의 단점 중 하나는 시퀀스 안의 토큰 위치 또는 순서에 대한 개념이 셀프 어텐션 메커니즘에 없다는것?????? (3장 참조)\n",
    "- deterministic(결정론적) 이라는 장점은 있지만,\n",
    "  - LLM 의 셀프 어텐션 메커니즘 자체가 위치 구애받지 않기 때문에 LLM 에 추가적인 위치 정부를 주입하는 것이 도움됨... (뭔소리야)\n",
    "- 어쨋든 위를 위해 두 종류의 위치를 고려한 임베딩을 사용할 수 있음\n",
    "  - 상대 위치 임베딩\n",
    "  - 절대 위치 임베딩: 시퀀스의 특정 위치에 직접 연관 됨\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c57079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e178d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(inputs)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48354e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n",
      "tensor([[ 0.4913,  1.1239,  1.4588,  ..., -0.3995, -1.8735, -0.1445],\n",
      "        [ 0.4481,  0.2536, -0.2655,  ...,  0.4997, -1.1991, -1.1844],\n",
      "        [-0.2507, -0.0546,  0.6687,  ...,  0.9618,  2.3737, -0.0528],\n",
      "        [ 0.9457,  0.8657,  1.6191,  ..., -0.4544, -0.7460,  0.3483]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)\n",
    "print(token_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f70b4e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "tensor([[ 1.7375, -0.5620, -0.6303,  ..., -0.2277,  1.5748,  1.0345],\n",
      "        [ 1.6423, -0.7201,  0.2062,  ...,  0.4118,  0.1498, -0.4628],\n",
      "        [-0.4651, -0.7757,  0.5806,  ...,  1.4335, -0.4963,  0.8579],\n",
      "        [-0.6754, -0.4628,  1.4323,  ...,  0.8139, -0.7088,  0.4827]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 절대 위치 임베딩\n",
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)\n",
    "print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d93a017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n",
      "tensor([[ 2.2288,  0.5619,  0.8286,  ..., -0.6272, -0.2987,  0.8900],\n",
      "        [ 2.0903, -0.4664, -0.0593,  ...,  0.9115, -1.0493, -1.6473],\n",
      "        [-0.7158, -0.8304,  1.2494,  ...,  2.3952,  1.8773,  0.8051],\n",
      "        [ 0.2703,  0.4029,  3.0514,  ...,  0.3595, -1.4548,  0.8310]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)\n",
    "print(input_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd89717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
